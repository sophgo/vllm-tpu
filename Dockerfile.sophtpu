# This vLLM Dockerfile is used to construct image that can build and run vLLM on Sophon TPU platform.

FROM ubuntu:22.04 AS base

ENV CCACHE_DIR=/root/.cache/ccache
ENV CMAKE_CXX_COMPILER_LAUNCHER=ccache
ENV DEBIAN_FRONTEND=noninteractive

ARG PYTHON_VERSION=3.11

# Install Python and other dependencies
RUN apt-get update -y \
    && apt-get install -y vim ccache software-properties-common git curl sudo \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update -y \
    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 \
    && update-alternatives --set python3 /usr/bin/python${PYTHON_VERSION} \
    && ln -sf /usr/bin/python${PYTHON_VERSION}-config /usr/bin/python3-config \
    && curl -sS https://bootstrap.pypa.io/get-pip.py | python${PYTHON_VERSION} \
    && python3 --version && python3 -m pip --version

RUN apt-get update -y \
    && apt-get install -y vim pandoc wget numactl gcc-12 g++-12 libtcmalloc-minimal4 libnuma-dev \
    && apt-get install -y ffmpeg libsm6 libxext6 libgl1 \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace

COPY requirements-common.txt requirements-common.txt
COPY requirements-sophtpu.txt requirements-sophtpu.txt
RUN pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cpu --force-reinstall \
    && pip install setuptools_scm \
    && pip install -r requirements-sophtpu.txt \
    && rm requirements-*.txt


COPY vllm /workspace/vllm
COPY tests/soph_test /workspace/tests/soph_test
#RUN --mount=type=cache,target=/root/.cache/pip \
#    --mount=type=cache,target=/root/.cache/ccache \
#    --mount=type=bind,source=.git,target=.git \
#    VLLM_TARGET_DEVICE=empty python3 setup.py develop

WORKDIR /workspace/
#RUN ln -s /workspace/vllm/tests && ln -s /workspace/vllm/examples && ln -s /workspace/vllm/benchmarks

# install development dependencies (for testing)
#RUN --mount=type=cache,target=/root/.cache/pip \
#    pip install -e tests/vllm_test_utils

#ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
