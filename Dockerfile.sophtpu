# This vLLM Dockerfile is used to construct image that can build and run vLLM on Sophon TPU platform.

FROM ubuntu:22.04 AS base

ENV CCACHE_DIR=/root/.cache/ccache
ENV CMAKE_CXX_COMPILER_LAUNCHER=ccache
ENV DEBIAN_FRONTEND=noninteractive

ARG PYTHON_VERSION=3.11

# Install Python and other dependencies
RUN apt-get update -y \
    && apt-get install -y ccache software-properties-common git curl sudo \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update -y \
    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 \
    && update-alternatives --set python3 /usr/bin/python${PYTHON_VERSION} \
    && ln -sf /usr/bin/python${PYTHON_VERSION}-config /usr/bin/python3-config \
    && curl -sS https://bootstrap.pypa.io/get-pip.py | python${PYTHON_VERSION} \
    && python3 --version && python3 -m pip --version
# Install uv for faster pip installs
RUN --mount=type=cache,target=/root/.cache/pip \
    python3 -m pip install uv

RUN --mount=type=cache,target=/var/cache/apt \
    apt-get update -y \
    && apt-get install -y wget numactl gcc-12 g++-12 libtcmalloc-minimal4 libnuma-dev \
    && apt-get install -y ffmpeg libsm6 libxext6 libgl1 \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace/vllm

COPY requirements-common.txt requirements-common.txt
COPY requirements-sophtpu.txt requirements-sophtpu.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    uv pip install --system -r requirements-sophtpu.txt \
    && uv pip install --system setuptools_scm \
    && uv pip install --system torch==2.1.0 --index-url https://download.pytorch.org/whl/cpu --force-reinstall

COPY . .
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/.cache/ccache \
    --mount=type=bind,source=.git,target=.git \
    VLLM_TARGET_DEVICE=empty python3 setup.py develop

WORKDIR /workspace/
#RUN ln -s /workspace/vllm/tests && ln -s /workspace/vllm/examples && ln -s /workspace/vllm/benchmarks

# install development dependencies (for testing)
#RUN --mount=type=cache,target=/root/.cache/pip \
#    pip install -e tests/vllm_test_utils

#ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
