# This vLLM Dockerfile is used to construct image that can build and run vLLM on Sophon TPU platform.

FROM ubuntu:22.04 AS build

ENV CCACHE_DIR=/root/.cache/ccache

ENV CMAKE_CXX_COMPILER_LAUNCHER=ccache

RUN --mount=type=cache,target=/var/cache/apt \
    apt-get update -y \
    && apt-get install -y curl ccache git wget vim numactl gcc-12 g++-12 python3 python3-pip libtcmalloc-minimal4 libnuma-dev \
    && apt-get install -y ffmpeg libsm6 libxext6 libgl1 \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12

WORKDIR /workspace/vllm

COPY requirements-common.txt requirements-common.txt
COPY requirements-sophtpu.txt requirements-sophtpu.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade pip \
    && pip install -v -r requirements-sophtpu.txt \
    && pip install setuptools_scm \
    && pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cpu --force-reinstall

COPY . .
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/.cache/ccache \
    --mount=type=bind,source=.git,target=.git \
    VLLM_TARGET_DEVICE=empty python3 setup.py develop

WORKDIR /workspace/
#RUN ln -s /workspace/vllm/tests && ln -s /workspace/vllm/examples && ln -s /workspace/vllm/benchmarks

# install development dependencies (for testing)
#RUN --mount=type=cache,target=/root/.cache/pip \
#    pip install -e tests/vllm_test_utils

#ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
